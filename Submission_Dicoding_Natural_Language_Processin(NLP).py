# -*- coding: utf-8 -*-
"""Submission_Dicoding_Natural_Language_Processin(NLP).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1phEOrPq05fXj0osAbIC4Si-G5deIeUXp

### **"Submission Dicoding Natural Language Processing(NLP) Dengan TensorFlow"**

**Nama : Bayu Prasetyo**

**Domisili : Kota Yogyakarta**

**Kelas Belajar : Belajar Pengembangan Machine Learning (Menengah) By Dicoding**

**Link Profil : https://www.dicoding.com/users/bayupras0301/academies**

**Sumber : Kaggle**

**Link Dataset :  https://www.kaggle.com/kishanyadav/inshort-news**

**Langkah-langkah awal dalam pengembangan model machine learning dimulai dengan memuat data yang akan digunakan. Setelah itu, modul dan pustaka yang diperlukan, seperti TensorFlow/Keras untuk pembuatan model, diimpor. Gaya visualisasi ditetapkan menggunakan seaborn untuk meningkatkan estetika plot.**

**Selanjutnya, dilakukan proses tokenisasi dan padding pada teks menggunakan Tokenizer dan pad_sequences dari TensorFlow/Keras, yang diperlukan untuk mengubah data teks menjadi bentuk yang dapat diproses oleh model machine learning. Model sequential dibangun dengan menambahkan lapisan-lapisan seperti Embedding, LSTM, dan Dense.**

**Data dibagi menjadi set pelatihan dan pengujian menggunakan train_test_split untuk mempersiapkan model. Konfigurasi model dilakukan dengan menentukan fungsi aktivasi, fungsi kerugian, optimizer, dan metrik yang sesuai untuk tujuan tertentu. Selanjutnya, model dilatih pada data pelatihan dan dievaluasi pada data pengujian. Untuk keperluan visualisasi, jika diperlukan, plot dapat dibuat dan ditampilkan menggunakan modul matplotlib.pyplot.**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import seaborn as sns
import io
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Flatten, Dropout, Dense

sns.set()
# %matplotlib inline

"""**Mengunggah file dari perangkat lokal ke sesi notebook Google Colab untuk digunakan dalam analisis atau pengolahan data di lingkungan Colab.**"""

from google.colab import files
import warnings
warnings.filterwarnings('ignore')
files = files.upload()

"""**Data dari file CSV yang diunggah akan diubah menjadi DataFrame pandas (news1 hingga news7), sehingga kita dapat melakukan manipulasi dan analisis data lebih lanjut di lingkungan Colab**"""

news1 = pd.read_csv(io.BytesIO(files['inshort_news_data-1 (3).csv']))
news2 = pd.read_csv(io.BytesIO(files['inshort_news_data-2 (3).csv']))
news3 = pd.read_csv(io.BytesIO(files['inshort_news_data-3 (2).csv']))
news4 = pd.read_csv(io.BytesIO(files['inshort_news_data-4 (2).csv']))
news5 = pd.read_csv(io.BytesIO(files['inshort_news_data-5 (2).csv']))
news6 = pd.read_csv(io.BytesIO(files['inshort_news_data-6 (2).csv']))
news7 = pd.read_csv(io.BytesIO(files['inshort_news_data-7 (2).csv']))

"""**Dengan menggunakan kode dibawah ini, DataFrame df akan berisi data yang digabungkan dari semua DataFrame dalam list data, dan indeks DataFrame akan diatur ulang menjadi indeks baru yang berurutan.**"""

data = [news1, news2, news3, news4, news5, news6, news7]
df = pd.concat(data, axis=0, ignore_index=True)
df.head()

"""**Gunakan kode "df.shape" untuk mengetahui dimensi (jumlah baris dan kolom) dari DataFrame df. Secara khusus, df.shape akan mengembalikan tupel yang berisi dua nilai**"""

df.shape

"""**Selanjutnya, Dengan gunakan kode dibawah ini, kolom 'Unnamed: 0' dan 'news_headline' akan dihapus dari DataFrame, dan DataFrame yang diperbarui akan ditampilkan. Ini dapat berguna jika kolom-kolom tersebut tidak diperlukan dalam analisis atau pemrosesan selanjutnya.**"""

df = df.drop(['Unnamed: 0', 'news_headline'], axis=1)
df.head()

"""**Penerapan Data Visualization**"""

plt.figure(figsize=(10,5))
sns.countplot(x='news_category', data=df)
plt.xticks(rotation=45)
plt.show()

"""**Dengan menggunakan kode dibawah ini, kita akan membuat representasi one-hot encoding dari kolom kategori dan menggabungkannya dengan DataFrame asli, kemudian menghapus kolom 'news_category' karena informasi tersebut sudah diwakili dalam bentuk one-hot encoding. DataFrame hasilnya adalah DataFrame baru (df2).**"""

review = pd.get_dummies(df['news_category'])
df2 = pd.concat([df, review], axis=1)
df2 = df2.drop('news_category', axis=1)
df2.head()

"""**Penggunaan Splitting, Validation Set 20%, Tokenizing, dan Padding**"""

X = df2['news_article'].values
y = df2.drop('news_article', axis=1).values
#split jadi train-test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)
tokenizer = Tokenizer(num_words=5000, oov_token='n')
tokenizer.fit_on_texts(X_train)
tokenizer.fit_on_texts(X_test)
sequence_train = tokenizer.texts_to_sequences(X_train)
sequence_test = tokenizer.texts_to_sequences(X_test)
padded_train = pad_sequences(sequence_train)
padded_test = pad_sequences(sequence_test)

"""**Penggunaan LSTM, Sequential, Embedding Dan Pelatihan Model**"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy') > 0.90):
      print('\nakurasi telah mencapai 90%')
      self.model.stop_training = True

callbacks = myCallback()
model = Sequential([
                    Embedding(input_dim=10000, output_dim=128),
                    LSTM(128),
                    Flatten(),
                    Dropout(0.5),
                    Dense(128, activation='relu'),
                    Dense(64, activation='relu'),
                    Dense(7, activation='softmax')
])
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(padded_train, y_train, epochs=62, validation_data=(padded_test, y_test), callbacks=[callbacks], batch_size=184)

"""**Implementasi Hasil Model Accuracy**"""

plt.figure(figsize=(8,5))
plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='validation_accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.ylim(ymin=0, ymax=1)
plt.show()

"""**Implementasi Hasil Model Loss**"""

plt.figure(figsize=(8,5))
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='validation_loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.ylim(ymin=0)
plt.show()